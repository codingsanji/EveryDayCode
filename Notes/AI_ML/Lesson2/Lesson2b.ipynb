{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a336792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ac278",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### **Supervised Learning**\n",
    "Type of machine learning where the model learns using labelled data. Labelled data as explained in `lesson2a` is data that has both input/training example and the correct answer.\n",
    "Formally, you give the model pairs (x,y) where,\n",
    "x = input features\n",
    "y = correct target\n",
    "The mode learns a function **f(x) → y** from this.\n",
    "\n",
    "*It has two branches and they include:*\n",
    "\n",
    "#### 1. **Classification:**\n",
    "- Process where a model learns how to recognize categories or classes by pattern so the output is a category or class label like : \n",
    "    - Spam vs Non-Spam\n",
    "    - Disease Type A / B \n",
    "    - Dog vs Cat\n",
    "\n",
    "- *Eg. demonstration:*\n",
    "    Assuming our data as points scattered across a 2D space -- some points belong to Class A, some to Class B. The model studies where these points tend to cluster and then figures out a boundary that separates them. That boundary could be a straight line, a curve or even something very complex depending on the model. Once it learns this boundary, the model can look at a new point and decide:\n",
    "    “Which side of the boundary is this on?” aaaaaand the answer becomes the predicted class/category.\n",
    "\n",
    "- Do note that there’s no numerical meaning to the classes. Class A isn’t “higher” or “lower” than Class B - they’re just different categories. The model simply learns patterns that distinguish one category from another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23735ba3",
   "metadata": {},
   "source": [
    "#### 2. **Regression:**\n",
    "- Process where a model learns the mathematical relationship between input features(x) and a continuous target value(y) to output a numerical value. Unlike classification where it decides which class something belongs to, the model estimates how much or how many. Used in cases like:\n",
    "    - Predicting the price of a house \n",
    "    - Estimating a student's mark this semester\n",
    "    - Predicting temperature and weather on a particular day\n",
    "\n",
    "- *Eg. demonstation:*\n",
    "    Imagine all your data points plotted on a graph where the x-axis represents the input (like square footage of a house) and the y-axis represents the target (like house price). These points won’t form a perfect straight line but they’ll show a general upward or downward pattern.\n",
    "\n",
    "    The model tries to capture that pattern by drawing the “best-fit line” (or curve) through the cloud of data points.\n",
    "    This line represents what the model has learned:\n",
    "    “As x increases or decreases, this is how y usually behaves.”\n",
    "\n",
    "    Now when the model gets a new input, it simply checks:\n",
    "    “Where would this new x fall on the learned line?”\n",
    "    The corresponding y-value becomes the predicted output.\n",
    "\n",
    "- Unlike classification, there is no concept of “boundaries” here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0ddda",
   "metadata": {},
   "source": [
    "---\n",
    "### Supervised Learning Flow\n",
    "\n",
    "#### **Phase 1: Training and Testing (Model Creation & Validation)**\n",
    "This phase involves training the algorithm and validating the resulting Statistical Model ($f(x)$) using labeled historical data.\n",
    "\n",
    "| Step | Component | Detailed Role / Percentage |\n",
    "| :--- | :--- | :--- |\n",
    "| 1 | **Historical Data** | The initial, labeled source dataset containing **input features** and their corresponding **known output labels**. |\n",
    "| 2 | **Random Sampling** | The process that randomly divides the Historical Data to create independent sets, ensuring both are representative of the whole. |\n",
    "| 3 | **Training Dataset** | **80%** of the data. This is the portion used by the Machine Learning algorithm to **learn** the underlying patterns and relationships. |\n",
    "| 4 | **Test Dataset** | **20%** of the data. This **hold-out set** is used exclusively to evaluate the model's performance on unseen data before deployment. |\n",
    "| 5 | **Machine Learning** | The computational process where the algorithm iteratively **fits** its parameters to the Training Dataset to minimize errors. |\n",
    "| 6 | **Statistical Model $f(x)$** | The resulting **learned function** (the hypothesis) from the training process, which generalizes the input-output mapping ($y = f(x)$). |\n",
    "| 7 | **Prediction and Testing** | The validated model ($f(x)$) makes predictions on the Test Dataset, which are then compared against the **known labels** to calculate accuracy. |\n",
    "| 8 | **Model Validation Outcome** | The quantitative result (e.g., accuracy score, F1-score) that determines if the model is robust and **fit for use** (meets pre-defined performance metrics). |\n",
    "\n",
    "---\n",
    "\n",
    "####  **Phase 2: Prediction (Deployment)**\n",
    "This phase involves using the validated model ($f(x)$) to generate output for new, unlabeled production data.\n",
    "\n",
    "| Component | Function in the Prediction Phase |\n",
    "| :--- | :--- |\n",
    "| **New Data** | Unseen, unlabeled production data that is fed into the deployed model to obtain a real-time output or forecast. |\n",
    "| **Model ($f(x)$)** | The validated Statistical Model from Phase 1, which now serves as the **prediction engine** in the production environment. |\n",
    "| **Prediction Outcome** | The final, calculated output (label or value) generated by the model for the New Data. |\n",
    "| **Improvement Note** | Prediction accuracy can be enhanced by **more training data**, increasing model **capacity** (complexity), or **algorithm redesign**. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b64e6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
