{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a336792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ac278",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### **Supervised Learning**\n",
    "Type of machine learning where the model learns using labelled data. Labelled data as explained in `lesson2a` is data that has both input/training example and the correct answer.\n",
    "Formally, you give the model pairs (x,y) where,\n",
    "x = input features\n",
    "y = correct target\n",
    "The mode learns a function **f(x) → y** from this.\n",
    "\n",
    "*It has two branches and they include:*\n",
    "#### 1. **Classification:**\n",
    "- Process where a model learns how to recognize categories or classes by pattern so the output is a category or class label like:\n",
    "    - Spam vs Non-Spam\n",
    "    - Disease Type A / B\n",
    "    - Dog vs Cat\n",
    "\n",
    "- *Eg. demonstration:*\n",
    "    Assuming our data as points scattered across a 2D space -- some points belong to Class A, some to Class B. The model studies where these points tend to cluster and then figures out a boundary that separates them. That boundary could be a straight line, a curve or even something very complex depending on the model. Once it learns this boundary, the model can look at a new point and decide:\n",
    "    “Which side of the boundary is this on?” aaaaaand the answer becomes the predicted class/category.\n",
    "\n",
    "- Do note that there’s no numerical meaning to the classes. Class A isn’t “higher” or “lower” than Class B - they’re just different categories. The model simply learns patterns that distinguish one category from another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23735ba3",
   "metadata": {},
   "source": [
    "#### 2. **Regression:**\n",
    "- Process where a model learns the mathematical relationship between input features(x) and a continuous target value(y) to output a numerical value. Unlike classification where it decides which class something belongs to, the model estimates how much or how many. Used in cases like:\n",
    "    - Predicting the price of a house \n",
    "    - Estimating a student's mark this semester\n",
    "    - Predicting temperature and weather on a particular day\n",
    "\n",
    "- *Eg. demonstration:*\n",
    "    Imagine all your data points plotted on a graph where the x-axis represents the input (like square footage of a house) and the y-axis represents the target (like house price). These points won’t form a perfect straight line but they’ll show a general upward or downward pattern.\n",
    "    The model tries to capture that pattern by drawing the “best-fit line” (or curve) through the cloud of data points.\n",
    "\n",
    "    This line represents what the model has learned:\n",
    "    “As x increases or decreases, this is how y usually behaves.”\n",
    "    Now when the model gets a new input, it simply checks:\n",
    "    “Where would this new x fall on the learned line?” The corresponding y-value becomes the predicted output. \n",
    "\n",
    "- Unlike classification, there is no concept of “boundaries” here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0ddda",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Workflow\n",
    "As discussed before, a machine learning project works in an iterative cycle.\n",
    "It is iterative because we can't possibly get everything perfect the first time. In order to better and perfect it, we need many iterations which teach us something new about the data and the problem. Here's a rough cycle of it,\n",
    "\n",
    "You look at data → clean it → build a model → evaluate it → realise something can be improved → go back → fix → try again.\n",
    "\n",
    "Let's dive into each of the steps of each iteration:\n",
    "\n",
    "#### 1. **Exploratory Data Analysis (EDA):**\n",
    "EDA is a method of analyzing datasets to summarize their main characteristics, often using visual methods.\n",
    "Here we use our raw data and question about it to obtain insights regarding the patterns in the data...but first, we split the data into \"seen\" and \"unseen\" data to make sure our insights are based on reviewing our \"seen\" sample data only.\n",
    "\n",
    "In summary this is what we explore:\n",
    "    1. Structure of the dataset\n",
    "        - How many records/rows do we have?\n",
    "            (Too few → model may not learn well.)\n",
    "        - How many features/columns?\n",
    "            Few features → simpler models like Linear/Logistic Regression\n",
    "            Many features → more powerful models like Random Forest, XGBoost, etc.\n",
    "        - What type of values exist inside those features?\n",
    "            (Numerical? Categorical? Text?)\n",
    "\n",
    "    2. Ranges and distributions\n",
    "        - Are numerical features spread widely?\n",
    "        - Are there extreme values (outliers)?\n",
    "        - Do some features have very low variety (same repeated value)? → Not useful.\n",
    "\n",
    "    3. Relationships\n",
    "        - Which features influence the target?\n",
    "        - How do features relate to each other? Highly correlated features = redundancy → may not be useful.\n",
    "\n",
    "    4. Possible enhancements\n",
    "        - Can we engineer new useful features from existing ones?\n",
    "        - Do we have enough valuable data to train a model effectively?\n",
    "\n",
    "    5. Potential issues\n",
    "        - Missing values\n",
    "        - Outliers\n",
    "        - Wrong/incorrect data types\n",
    "        - Imbalanced classes (important in classification tasks)\n",
    "        - Too few meaningful samples\n",
    "        - Need for encoding categorical features\n",
    "        - Need for scaling numerical features\n",
    "\n",
    "#### 2. **Pre-processing:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f1591",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
