{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb77a8d",
   "metadata": {},
   "source": [
    "## Key terms:\n",
    "\n",
    "#### **Artificial Intelligence (AI)**\n",
    "Artificial Intelligence is a major field in computer science focused on **creating intelligent agents** capable of **perceiving their environment, learning from experience, reasoning about information and making decisions** to achieve specific goals. It aims to **replicate or simulate human cognitive abilities** such as learning, problem-solving, planning, and language understanding.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be07831",
   "metadata": {},
   "source": [
    "\n",
    "#### **Deep Learning (DL)**\n",
    "Deep Learning is a sub-area of Machine Learning (and a sub-sub-area of Artificial Intelligence) that uses **artificial neural networks (ANNs)** inspired by the structure and function of the human brain.\n",
    "\n",
    "These networks contain **multiple layers** that allow them to automatically learn increasingly complex features from large amounts of data. It excels in tasks like **image recognition, speech processing, natural language understanding and autonomous systems** where traditional ML methods may struggle.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690208e",
   "metadata": {},
   "source": [
    "#### **Transfer Learning (TL)**\n",
    "It is a technique where a model that has already learned something from a large dataset is re-used for a new, related task. Instead of training a whole new model from zero which would take a significant amount of time and data, we can just take a pre-trained model, keep what it has already learned and fine-tune it to match the new purpose it must serve.\n",
    "\n",
    "This works because machine learning models (especially deep learning models) learn general patterns in each layer that can be used again in multiple places after modification. Like for instance, a model trained on cars will learn shapes, parts, curves, textures etc. and these are not specific to just cars but they also appear in other objects like animals, furniture etc. \n",
    "\n",
    "*Common Use Cases:*\n",
    "- Image classification (CNN-based models)  \n",
    "- Natural language processing (BERT, GPT, etc.)  \n",
    "- Audio and speech recognition  \n",
    "- Medical image analysis  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739374c",
   "metadata": {},
   "source": [
    "\n",
    "#### **Machine Learning (ML)**\n",
    "Machine Learning is a **method of AI** that enables systems to learn patterns from data **without being explicitly programmed** to perform a task. Instead of following hard-coded instructions as in traditional programming, ML models **improve their performance automatically** by analyzing data, identifying patterns and making predictions or decisions based on that experience.\n",
    "\n",
    "**ML has the following steps/framework:**  \n",
    "ML follows an **iterative cycle** (meaning we often repeat steps multiple times to improve accuracy, performance, and general reliability).\n",
    "\n",
    "\n",
    "### **1. Problem Definition**\n",
    "This step is crucial because it determines the **architecture, approach, and type of model** we will use. It involves the process of defining:\n",
    "\n",
    "- **The goal of the project**  \n",
    "- **What we want the model to predict or detect**  \n",
    "- **The type of output we want/need**\n",
    "\n",
    "*Sample approach:*\n",
    "\n",
    "- Are we predicting a number? → *Regression*  \n",
    "- Are we predicting a category? → *Classification*  \n",
    "- Are we grouping similar items? → *Unsupervised learning*\n",
    "\n",
    "*Types of learning approaches include:*\n",
    "\n",
    "- **Supervised learning**  \n",
    "  - The model is trained on labeled data (every training example includes both the input and correct output). The model learns the relationship between them and uses this knowledge to make predictions on new data.\n",
    "  - Task examples:\n",
    "    - Classification (predicting categories)\n",
    "    - Regression (predicting numerical values)  \n",
    "  - Eg.: Predicting house prices, Predicting if a mail is spam or not etc.\n",
    "\n",
    "- **Unsupervised learning**  \n",
    "  - Data has no labels (model tries to find hidden structures or patterns by itself since no correct answers are provided). In this kind of learning, the model groups similar data points or reduces data complexity [data is generally said to be complex if it has a large number of features, if there's noise in the data (as in, there is random or irrelevant info), if groups/clusters overlap, if there exists unusual data points that can confuse the model or distort clusters etc.]\n",
    "  - Task examples:\n",
    "    - Clustering (grouping similar items together)\n",
    "    - Dimensionality Reduction (simplifying large datasets)\n",
    "  - Eg.: Customer segmentation (model takes purchase behavior and groups customers automatically into categories like \"frequent buyers\", \"bargain seekers\" or \"premium customers\").\n",
    "\n",
    "- **Semi-supervised learning**  \n",
    "  - Mix of both supervised/labeled and unsupervised/unlabeled data. It generally uses a small amount of labelled data and a larger amount of unlabelled data.\n",
    "  - It is helpful when labeling is costly, slow or requires domain experts like in the following example uses:\n",
    "    - Medical imaging\n",
    "    - Speech recognition etc....\n",
    "  - It provides better performance than unsupervised learning and is significantly cheaper than fully supervised learning.\n",
    "\n",
    "- **Reinforcement learning**  \n",
    "  - Here, an agent learns by interacting with an environment and receiving rewards or penalties based on its actions so there is no fixed dataset (since the agent learns by trial and error). The goal here is to maximize the total rewards over time.\n",
    "  - The agent makes decisions step by step, learns which move yields the highest rewards and gradually becomes better at achieving its goal.\n",
    "  - Eg.: Game-playing AI, robotics navigation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Data Collection & Understanding**\n",
    "This step involves gathering the data needed for training and understanding its quality, structure, and limitations.\n",
    "\n",
    "*Types of data include:*\n",
    "\n",
    "- **Structured data**  \n",
    "  - Highly organized data that follows a clearly defined format [usually in tables (rows and columns)]. Since it is well-organized, it is easy to store, search, filter and analyze using traditional tools.\n",
    "  - Eg.: Excel sheets, CSV files, SQL tables.\n",
    "  - Structured data is simple, clean and predictable making it the easiest form of data for traditional machine learning.\n",
    "\n",
    "- **Unstructured data**  \n",
    "  - This type of data is more \"free-form\"… meaning it does NOT have a fixed format or predefined structure thus making it hard to place into rows or columns. This type of data is harder to process since it is more complex and richer.\n",
    "  - Eg.: images, audio recordings, videos, raw text.\n",
    "  - Most of the data we generate today through phones, cameras, websites etc. are unstructured. Deep learning excels in extracting meaning from this kind of data.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Evaluation (Defining Success)**\n",
    "In this step, we raise the question of **\"How do we know our model is good?\"** to decide what is \"good\" when it comes to our model. Different problems require different evaluation methods so choosing the right metric is essential to properly judge performance.\n",
    "\n",
    "Metrics are measurement tools we use to evaluate how good a model is. They let us know how close, accurate and/or reliable the model's predictions are.\n",
    "\n",
    "Eg.: (these will be elaborated in the next sections of lesson 2)\n",
    "\n",
    "- **Regression (predicting numbers)**  \n",
    "  - Metrics:\n",
    "    - MAE (Mean Absolute Error) – measures average absolute difference  \n",
    "    - MSE (Mean Squared Error) – penalizes larger mistakes  \n",
    "    - RMSE (Root Mean Squared Error) – widely used for forecasting\n",
    "\n",
    "- **Classification (predicting categories)**  \n",
    "  - Metrics:\n",
    "    - Accuracy – overall correctness  \n",
    "    - Precision – how many predicted positives were correct  \n",
    "    - Recall – how many actual positives we identified  \n",
    "    - F1 score – balance of precision + recall  \n",
    "    - Confusion matrix – visual breakdown of predictions\n",
    "\n",
    "- **Forecasting (time series)**  \n",
    "  - MAE  \n",
    "  - MSE  \n",
    "  - RMSE  \n",
    "  - MAPE (percentage error)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Feature Engineering & Selection**\n",
    "Columns that are inputted into our model and used to make predictions in future (since models learn from them) are called **\"features\"** *(taken from Lesson3b)*.\n",
    "\n",
    "Feature engineering is the process of using domain knowledge to select, transform and create variables (features) from raw data to improve the model's performance. It generally includes the following:\n",
    "\n",
    "- Creating new useful features  \n",
    "- Removing irrelevant ones  \n",
    "- Scaling or transforming data  \n",
    "- Selecting the most important features\n",
    "\n",
    "Eg.: Heart disease prediction model's features may include:\n",
    "\n",
    "- Age  \n",
    "- Weight  \n",
    "- Sex  \n",
    "- Blood Pressure  \n",
    "- Chest Pain Type  \n",
    "- Cholesterol Level  \n",
    "etc...\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Modelling**\n",
    "In this step, we choose the **type of algorithm** and train the model using the features and data.\n",
    "Eg. model choices since different models work better for different problems:\n",
    "\n",
    "**For Tabular Data:**\n",
    "- Linear Regression  \n",
    "- Random Forest  \n",
    "- XGBoost  \n",
    "- Decision Trees  \n",
    "\n",
    "**For Images:**\n",
    "- CNNs (Convolutional Neural Networks)\n",
    "\n",
    "**For Text / Sequences:**\n",
    "- RNNs  \n",
    "- LSTMs  \n",
    "- Transformers\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Experimentation**\n",
    "This step involves testing and improving the model by:\n",
    "- Trying different algorithms  \n",
    "- Adjusting hyperparameters  \n",
    "- Collecting more data  \n",
    "- Adding / removing features  \n",
    "- Improving preprocessing\n",
    "\n",
    "ML development is **iterative**, so we repeat this step until we reach the best possible performance.\n",
    "\n",
    "---\n",
    "**Ethics:**\n",
    "- One major challenge is anonymising data.\n",
    "  Even when we remove names and contact details, identifying a person is still surprisingly easy. For example, a patient can often be uniquely identified using just postcode, birth date and gender.\n",
    "  So \"anonymous\" data is rarely truly anonymous.\n",
    "\n",
    "- Another ethical concern comes from how ML models can end up discriminating against certain groups.\n",
    "  The algorithm itself doesn’t 'want' to discriminate but if the data contains biased patterns, the model will learn and repeat those biases.\n",
    "  A classic example is loan applications.\n",
    "  If the model uses features such as gender, religion, or race, the result is immediately unethical even if the algorithm claims it’s 'just using the data'.\n",
    "\n",
    "Therefore because of these risks, we must always ask:\n",
    "\n",
    "1. Who is allowed to access the data?\n",
    "Data often contains highly sensitive information, so access must be controlled.\n",
    "\n",
    "2. For what purpose was the data collected?\n",
    "Using data for purposes the user didn’t agree to is unethical (and sometimes illegal).\n",
    "\n",
    "3. What conclusions can we legitimately draw from it?\n",
    "Predictions seem precise but they are still based on probability, noise and incomplete information.\n",
    "\n",
    "This is why all ML results need to come with caveats or disclaimers.\n",
    "Statistical arguments alone are never enough...they must be supported by context, ethical consideration and an understanding of the limitations of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539806ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data\n",
    "Data today is generated constantly because electronic devices are everywhere. Everything we do on a device produces some form of data --- clicks, messages, sensor readings, app usage etc.\n",
    "\n",
    "However, the amount of data generated is increasing too rapidly as compared to our ability to understand it. This creates a gap that machine learning helps bridge thus making it easy for us to make sense of the massive amount of information that is hidden inside the data. \n",
    "\n",
    "**Real world data** unlike the data we have so far worked with are almost never clean and/or complete. They usually have :\n",
    "- Incomplete combinations:\n",
    "    The number of actual instances is much smaller than the total possible attribute combinations.\n",
    "\n",
    "- Sparse data:\n",
    "    Many values are zero or missing.\n",
    "\n",
    "- Missing values:\n",
    "    Attributes may not be recorded for every example.\n",
    "\n",
    "- Noise:\n",
    "    Human errors, device inaccuracies, wrong labels.\n",
    "\n",
    "- Non-deterministic behavior:\n",
    "    In real life, decisions are often based on probability, not fixed rules.\n",
    "\n",
    "As explained above in the ML section's 2nd part, Data types can be differentiated into 2 types : Structured data and Unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf807a1e",
   "metadata": {},
   "source": [
    "---\n",
    "## Python Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a724635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d6db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Google Colab!\n",
      "x: 10 <class 'int'>\n",
      "y: 3.14 <class 'float'>\n",
      "name: Sunny <class 'str'>\n",
      "is_phd: True <class 'bool'>\n",
      "Fruits: ['apple', 'banana', 'cherry']\n",
      "First fruit: apple\n",
      "I like apple\n",
      "I like banana\n",
      "I like cherry\n",
      "You are an adult.\n",
      "Hello Sunny, welcome to Python!\n",
      "Student info: {'name': 'Sunny', 'age': 27, 'field': 'AI'}\n",
      "Name: Sunny\n",
      "NumPy array: [1 2 3 4 5]\n",
      "Mean: 3.0\n",
      "Pandas DataFrame:\n",
      "      Name  Age\n",
      "0    Alice   24\n",
      "1      Bob   30\n",
      "2  Charlie   22\n"
     ]
    }
   ],
   "source": [
    "# 1. Hello World\n",
    "print(\"Hello, Google Colab!\")\n",
    "\n",
    "# 2. Variables & Data Types\n",
    "x = 10        # integer\n",
    "y = 3.14      # float\n",
    "name = \"Sunny\"  # string\n",
    "is_phd = True   # boolean\n",
    "\n",
    "print(\"x:\", x, type(x))\n",
    "print(\"y:\", y, type(y))\n",
    "print(\"name:\", name, type(name))\n",
    "print(\"is_phd:\", is_phd, type(is_phd))\n",
    "\n",
    "# 3. Lists\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "print(\"Fruits:\", fruits)\n",
    "print(\"First fruit:\", fruits[0])\n",
    "\n",
    "# 4. Loops\n",
    "for fruit in fruits:\n",
    "    print(\"I like\", fruit)\n",
    "\n",
    "# 5. If-Else\n",
    "age = 21\n",
    "if age >= 18:\n",
    "    print(\"You are an adult.\")\n",
    "else:\n",
    "    print(\"You are a minor.\")\n",
    "\n",
    "# 6. Functions\n",
    "def greet(person):\n",
    "    return f\"Hello {person}, welcome to Python!\"\n",
    "\n",
    "print(greet(\"Sunny\"))\n",
    "\n",
    "# 7. Dictionaries\n",
    "student = {\"name\": \"Sunny\", \"age\": 27, \"field\": \"AI\"}\n",
    "print(\"Student info:\", student)\n",
    "print(\"Name:\", student[\"name\"])\n",
    "\n",
    "# 8. Using NumPy (numerical operations)\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"NumPy array:\", arr)\n",
    "print(\"Mean:\", arr.mean())\n",
    "\n",
    "# 9. Using Pandas (data tables)\n",
    "import pandas as pd\n",
    "data = {\"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Age\": [24, 30, 22]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Pandas DataFrame:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
